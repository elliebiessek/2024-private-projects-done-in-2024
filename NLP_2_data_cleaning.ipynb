{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info alertinfo\" style=\"margin-top: 0px\">\n",
    "<h1> Natural Language Processing with Disaster Tweets </h1>\n",
    "part 2 - data cleaning\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Imports </h1>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard\n",
    "import pandas as pd\n",
    "\n",
    "# NLP\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. read data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "test_set = pd.read_csv('test.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Data cleaning </h1>\n",
    "\n",
    "- To keep the code clean, the investigation of what cleaning functions are needed is not included here in full.\n",
    "- Each text may require different cleaning steps, so it is important to check the data and adjust the cleaning steps accordingly.\n",
    "- Cleaning functions are also udjusted/added when evaluating model accuracy as thats when we can see why some texts are missclassified.\n",
    "- Typically this process involves many 'going back and forth' adjustments - here I show just one\n",
    "- I also show the logic - why those changes were made.\n",
    "\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. missing values\n",
    "since we are interest in strings we will replace each missing value with ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7613 rows in the original data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>dtypes</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Uniques</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>7613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>keyword</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>location</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>3342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>target</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  dtypes  Missing  Uniques\n",
       "0        id   int64        0     7613\n",
       "1   keyword  object        0      222\n",
       "2  location  object        0     3342\n",
       "3      text  object        0     7503\n",
       "4    target   int64        0        2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill missing values with empty string\n",
    "def summary_table(df):\n",
    "    '''\n",
    "    Creates a summary info tableabout given data frame\n",
    "    \n",
    "    Args:\n",
    "        df: data frame\n",
    "        \n",
    "    Returns:\n",
    "        summary: info data frame\n",
    "    '''\n",
    "    print('There are {} rows in the original data'.format(df.shape[0]))\n",
    "    summary = pd.DataFrame(df.dtypes, columns = ['dtypes'])\n",
    "    summary = summary.reset_index()\n",
    "    summary['Name'] = summary['index']\n",
    "    summary = summary[['Name', 'dtypes']]\n",
    "    summary['Missing'] = df.isnull().sum().values\n",
    "    summary['Uniques'] = df.nunique().values\n",
    "    return summary\n",
    "\n",
    "df.fillna('', inplace=True)\n",
    "summary_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. pre-clean and corpus set up\n",
    "first cleaning function that will be updated later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions 1 (those are initial definitions - we might adjust them later when re-evaluating our models)\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def remove_urls(text):\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_emails(text):\n",
    "    text = re.sub(r'\\S+@\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'(^|\\s)@\\w+', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "def remove_foreign_characters(text):\n",
    "    text = re.sub(r'([^\\x00-\\x7F])+', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_short_words(text):\n",
    "    text = ' '.join([word for word in text.split() if len(word) > 2])\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stopwords = set(STOPWORDS)\n",
    "    return ' '.join([word for word in text.split() if word.lower() not in stopwords])\n",
    "\n",
    "def remove_symbols_and_numbers(text):\n",
    "    text = ''.join(' ' if not c.isalpha() else c for c in text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "def clean_phase_1(text):\n",
    "    text = text.lower()\n",
    "    text = remove_urls(text)\n",
    "    text = remove_emails(text)\n",
    "    text = remove_foreign_characters(text)\n",
    "    text = remove_symbols_and_numbers(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = remove_short_words(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_words = set(words.words())\n",
    "\n",
    "# find 'important words' - 'keywords' in our training set\n",
    "data = df.copy()\n",
    "feature_name = 'keyword'\n",
    "data[feature_name] = data[feature_name].apply(clean_phase_1)\n",
    "set_values = set(data[feature_name].values)\n",
    "set_values.remove('')\n",
    "important_words = set()\n",
    "for value in set_values:\n",
    "    words = value.split()\n",
    "    important_words.update(words)\n",
    "\n",
    "# find 'unimportant words' - 'locations' in our training set\n",
    "feature_name = 'location'\n",
    "data[feature_name] = data[feature_name].apply(clean_phase_1)\n",
    "set_values = ' '.join(data[feature_name].dropna())\n",
    "set_values = set_values.split()\n",
    "set_values = set([word for word in set_values if len(word) > 2])\n",
    "unimportant_words = set()\n",
    "for value in set_values:\n",
    "    words = value.split()\n",
    "    unimportant_words.update(words)\n",
    "words_to_keep = unimportant_words.intersection(important_words)\n",
    "unimportant_words = unimportant_words - words_to_keep\n",
    "\n",
    "# updating corpus\n",
    "english_words.update(important_words)\n",
    "english_words = english_words - unimportant_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data words\n",
    "feature_name = 'text'\n",
    "data[feature_name] = data[feature_name].apply(clean_phase_1)\n",
    "all_text = ' '.join(data['text'].dropna())\n",
    "words = all_text.split()\n",
    "word_counts = Counter(words)\n",
    "word_counts_df = pd.DataFrame.from_dict(word_counts, orient='index', columns=['count']).reset_index()\n",
    "word_counts_df.columns = ['word', 'count']\n",
    "word_counts_df = word_counts_df.sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "data_words_df = word_counts_df[word_counts_df['count'] >= 5]\n",
    "train_data_words = set(data_words_df['word'].values)\n",
    "\n",
    "train_words_common = train_data_words.intersection(english_words)\n",
    "train_words_uncommon = train_data_words - train_words_common\n",
    "\n",
    "# updating corpus\n",
    "english_words.update(train_data_words) # all words on the first phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>processed text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>reason earthquak may allah forgiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resid ask shelter place notifi offic evacu she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>peopl receiv wildfir evacu order california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got sent photo rubi alaska smoke wildfir school</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1                   Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4                              Forest fire near La Ronge Sask. Canada   \n",
       "2   5                   All residents asked to 'shelter in place' are ...   \n",
       "3   6                   13,000 people receive #wildfires evacuation or...   \n",
       "4   7                   Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                     processed text  \n",
       "0       1                  reason earthquak may allah forgiv  \n",
       "1       1                            forest fire near canada  \n",
       "2       1  resid ask shelter place notifi offic evacu she...  \n",
       "3       1        peopl receiv wildfir evacu order california  \n",
       "4       1    got sent photo rubi alaska smoke wildfir school  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare_for_ml\n",
    "def filter_words(text, english_words, filter=True):\n",
    "    if filter:\n",
    "        words = text.split()\n",
    "        text = ' '.join([word for word in words if word.lower() in english_words])\n",
    "    return text\n",
    "\n",
    "def stem_text(text):\n",
    "    porter = PorterStemmer()\n",
    "    words = word_tokenize(text)\n",
    "    stemmed_words = [porter.stem(word) for word in words]\n",
    "    stemmed_text = ' '.join(stemmed_words)\n",
    "    return stemmed_text\n",
    "\n",
    "def prepare_for_ml(data, english_words):\n",
    "    data.fillna('', inplace=True)\n",
    "    data['keyword'] = data['keyword'].apply(clean_phase_1)\n",
    "    data['keyword'] = data['keyword'].apply(lambda x: filter_words(x, english_words, filter)).apply(stem_text)\n",
    "    data['processed text'] = data['text'].apply(clean_phase_1)\n",
    "    data['processed text'] = data['processed text'].apply(lambda x: filter_words(x, english_words, filter)).apply(stem_text)\n",
    "    return data\n",
    "\n",
    "df = prepare_for_ml(df, english_words)\n",
    "test_set = prepare_for_ml(test_set, english_words)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we are now ready for part 3 - building ML models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
