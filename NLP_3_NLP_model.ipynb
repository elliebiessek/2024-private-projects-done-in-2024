{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info alertinfo\" style=\"margin-top: 0px\">\n",
    "<h1> Natural Language Processing with Disaster Tweets </h1>\n",
    "part 3 - machine learning\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Imports </h1>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# NLP\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "\n",
    "# visualization\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# others\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. read data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "test_set = pd.read_csv('test.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Data cleaning </h1>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pre-clean and corpus set up\n",
    "first cleaning function that will be updated later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions 1\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def remove_urls(text):\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_emails(text):\n",
    "    text = re.sub(r'\\S+@\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'(^|\\s)@\\w+', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "def remove_foreign_characters(text):\n",
    "    text = re.sub(r'([^\\x00-\\x7F])+', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_short_words(text):\n",
    "    text = ' '.join([word for word in text.split() if len(word) > 2])\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stopwords = set(STOPWORDS)\n",
    "    return ' '.join([word for word in text.split() if word.lower() not in stopwords])\n",
    "\n",
    "def remove_symbols_and_numbers(text):\n",
    "    text = ''.join(' ' if not c.isalpha() else c for c in text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "def clean_phase_1(text):\n",
    "    text = text.lower()\n",
    "    text = remove_urls(text)\n",
    "    text = remove_emails(text)\n",
    "    text = remove_foreign_characters(text)\n",
    "    text = remove_symbols_and_numbers(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = remove_short_words(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['destroyed', 'destroy', 'tsunami', 'landslide', 'meltdown']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_words = set(words.words())\n",
    "\n",
    "# find 'important words' - 'keywords' in our training set\n",
    "data = df.copy()\n",
    "feature_name = 'keyword'\n",
    "data[feature_name] = data[feature_name].apply(clean_phase_1)\n",
    "set_values = set(data[feature_name].values)\n",
    "set_values.remove('')\n",
    "important_words = set()\n",
    "for value in set_values:\n",
    "    words = value.split()\n",
    "    important_words.update(words)\n",
    "    \n",
    "examples = list(important_words)[:5]\n",
    "examples   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doflamingo', 'brazos', 'cairo', 'bandar', 'berhati']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find 'unimportant words' - 'locations' in our training set\n",
    "feature_name = 'location'\n",
    "data[feature_name] = data[feature_name].apply(clean_phase_1)\n",
    "set_values = ' '.join(data[feature_name].dropna())\n",
    "set_values = set_values.split()\n",
    "set_values = set([word for word in set_values if len(word) > 2])\n",
    "unimportant_words = set()\n",
    "for value in set_values:\n",
    "    words = value.split()\n",
    "    unimportant_words.update(words)\n",
    "words_to_keep = unimportant_words.intersection(important_words)\n",
    "unimportant_words = unimportant_words - words_to_keep\n",
    "\n",
    "examples = list(unimportant_words)[:5]\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating corpus\n",
    "english_words.update(important_words)\n",
    "english_words = english_words - unimportant_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data words\n",
    "feature_name = 'text'\n",
    "data[feature_name] = data[feature_name].apply(clean_phase_1)\n",
    "all_text = ' '.join(data['text'].dropna())\n",
    "words = all_text.split()\n",
    "word_counts = Counter(words)\n",
    "word_counts_df = pd.DataFrame.from_dict(word_counts, orient='index', columns=['count']).reset_index()\n",
    "word_counts_df.columns = ['word', 'count']\n",
    "word_counts_df = word_counts_df.sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "data_words_df = word_counts_df[word_counts_df['count'] >= 5]\n",
    "train_data_words = set(data_words_df['word'].values)\n",
    "\n",
    "train_words_common = train_data_words.intersection(english_words)\n",
    "train_words_uncommon = train_data_words - train_words_common\n",
    "\n",
    "# updating corpus\n",
    "english_words.update(train_data_words) # all words on the first phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. prepare for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>processed text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>reason earthquak may allah forgiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resid ask shelter place notifi offic evacu she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>peopl receiv wildfir evacu order california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got sent photo rubi alaska smoke wildfir school</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1                   Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4                              Forest fire near La Ronge Sask. Canada   \n",
       "2   5                   All residents asked to 'shelter in place' are ...   \n",
       "3   6                   13,000 people receive #wildfires evacuation or...   \n",
       "4   7                   Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                     processed text  \n",
       "0       1                  reason earthquak may allah forgiv  \n",
       "1       1                            forest fire near canada  \n",
       "2       1  resid ask shelter place notifi offic evacu she...  \n",
       "3       1        peopl receiv wildfir evacu order california  \n",
       "4       1    got sent photo rubi alaska smoke wildfir school  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare_for_ml\n",
    "def filter_words(text, english_words, filter=True):\n",
    "    if filter:\n",
    "        words = text.split()\n",
    "        text = ' '.join([word for word in words if word.lower() in english_words])\n",
    "    return text\n",
    "\n",
    "def stem_text(text):\n",
    "    porter = PorterStemmer()\n",
    "    words = word_tokenize(text)\n",
    "    stemmed_words = [porter.stem(word) for word in words]\n",
    "    stemmed_text = ' '.join(stemmed_words)\n",
    "    return stemmed_text\n",
    "\n",
    "def prepare_for_ml(data, english_words):\n",
    "    data.fillna('', inplace=True)\n",
    "    data['keyword'] = data['keyword'].apply(clean_phase_1)\n",
    "    data['keyword'] = data['keyword'].apply(lambda x: filter_words(x, english_words, filter)).apply(stem_text)\n",
    "    data['processed text'] = data['text'].apply(clean_phase_1)\n",
    "    data['processed text'] = data['processed text'].apply(lambda x: filter_words(x, english_words, filter)).apply(stem_text)\n",
    "    return data\n",
    "\n",
    "df = prepare_for_ml(df, english_words)\n",
    "test_set = prepare_for_ml(test_set, english_words)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Vectorising </h1>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aal</th>\n",
       "      <th>aba</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abc</th>\n",
       "      <th>abil</th>\n",
       "      <th>abject</th>\n",
       "      <th>abl</th>\n",
       "      <th>ablaz</th>\n",
       "      <th>aboard</th>\n",
       "      <th>abomin</th>\n",
       "      <th>...</th>\n",
       "      <th>zaman</th>\n",
       "      <th>zar</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zodiac</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5507 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aal  aba  abandon       abc  abil  abject  abl  ablaz  aboard  abomin  \\\n",
       "0     0.0  0.0      0.0  0.000000   0.0     0.0  0.0    0.0     0.0     0.0   \n",
       "1     0.0  0.0      0.0  0.000000   0.0     0.0  0.0    0.0     0.0     0.0   \n",
       "2     0.0  0.0      0.0  0.000000   0.0     0.0  0.0    0.0     0.0     0.0   \n",
       "3     0.0  0.0      0.0  0.000000   0.0     0.0  0.0    0.0     0.0     0.0   \n",
       "4     0.0  0.0      0.0  0.000000   0.0     0.0  0.0    0.0     0.0     0.0   \n",
       "...   ...  ...      ...       ...   ...     ...  ...    ...     ...     ...   \n",
       "7608  0.0  0.0      0.0  0.000000   0.0     0.0  0.0    0.0     0.0     0.0   \n",
       "7609  0.0  0.0      0.0  0.000000   0.0     0.0  0.0    0.0     0.0     0.0   \n",
       "7610  0.0  0.0      0.0  0.000000   0.0     0.0  0.0    0.0     0.0     0.0   \n",
       "7611  0.0  0.0      0.0  0.000000   0.0     0.0  0.0    0.0     0.0     0.0   \n",
       "7612  0.0  0.0      0.0  0.416642   0.0     0.0  0.0    0.0     0.0     0.0   \n",
       "\n",
       "      ...  zaman  zar  zeal  zionist  zip  zipper  zodiac  zombi  zone  zoom  \n",
       "0     ...    0.0  0.0   0.0      0.0  0.0     0.0     0.0    0.0   0.0   0.0  \n",
       "1     ...    0.0  0.0   0.0      0.0  0.0     0.0     0.0    0.0   0.0   0.0  \n",
       "2     ...    0.0  0.0   0.0      0.0  0.0     0.0     0.0    0.0   0.0   0.0  \n",
       "3     ...    0.0  0.0   0.0      0.0  0.0     0.0     0.0    0.0   0.0   0.0  \n",
       "4     ...    0.0  0.0   0.0      0.0  0.0     0.0     0.0    0.0   0.0   0.0  \n",
       "...   ...    ...  ...   ...      ...  ...     ...     ...    ...   ...   ...  \n",
       "7608  ...    0.0  0.0   0.0      0.0  0.0     0.0     0.0    0.0   0.0   0.0  \n",
       "7609  ...    0.0  0.0   0.0      0.0  0.0     0.0     0.0    0.0   0.0   0.0  \n",
       "7610  ...    0.0  0.0   0.0      0.0  0.0     0.0     0.0    0.0   0.0   0.0  \n",
       "7611  ...    0.0  0.0   0.0      0.0  0.0     0.0     0.0    0.0   0.0   0.0  \n",
       "7612  ...    0.0  0.0   0.0      0.0  0.0     0.0     0.0    0.0   0.0   0.0  \n",
       "\n",
       "[7613 rows x 5507 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = df['processed text'].tolist()\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Convert the TF-IDF matrix to a DataFrame (optional)\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aal</th>\n",
       "      <th>aba</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abc</th>\n",
       "      <th>abil</th>\n",
       "      <th>abject</th>\n",
       "      <th>abl</th>\n",
       "      <th>ablaz</th>\n",
       "      <th>aboard</th>\n",
       "      <th>abomin</th>\n",
       "      <th>...</th>\n",
       "      <th>zaman</th>\n",
       "      <th>zar</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zodiac</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 5507 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aal  aba  abandon  abc  abil  abject  abl  ablaz  aboard  abomin  ...  \\\n",
       "0     0.0  0.0      0.0  0.0   0.0     0.0  0.0    0.0     0.0     0.0  ...   \n",
       "1     0.0  0.0      0.0  0.0   0.0     0.0  0.0    0.0     0.0     0.0  ...   \n",
       "2     0.0  0.0      0.0  0.0   0.0     0.0  0.0    0.0     0.0     0.0  ...   \n",
       "3     0.0  0.0      0.0  0.0   0.0     0.0  0.0    0.0     0.0     0.0  ...   \n",
       "4     0.0  0.0      0.0  0.0   0.0     0.0  0.0    0.0     0.0     0.0  ...   \n",
       "...   ...  ...      ...  ...   ...     ...  ...    ...     ...     ...  ...   \n",
       "3258  0.0  0.0      0.0  0.0   0.0     0.0  0.0    0.0     0.0     0.0  ...   \n",
       "3259  0.0  0.0      0.0  0.0   0.0     0.0  0.0    0.0     0.0     0.0  ...   \n",
       "3260  0.0  0.0      0.0  0.0   0.0     0.0  0.0    0.0     0.0     0.0  ...   \n",
       "3261  0.0  0.0      0.0  0.0   0.0     0.0  0.0    0.0     0.0     0.0  ...   \n",
       "3262  0.0  0.0      0.0  0.0   0.0     0.0  0.0    0.0     0.0     0.0  ...   \n",
       "\n",
       "      zaman  zar  zeal  zionist  zip  zipper  zodiac  zombi  zone  zoom  \n",
       "0       0.0  0.0   0.0      0.0  0.0     0.0     0.0    0.0   0.0   0.0  \n",
       "1       0.0  0.0   0.0      0.0  0.0     0.0     0.0    0.0   0.0   0.0  \n",
       "2       0.0  0.0   0.0      0.0  0.0     0.0     0.0    0.0   0.0   0.0  \n",
       "3       0.0  0.0   0.0      0.0  0.0     0.0     0.0    0.0   0.0   0.0  \n",
       "4       0.0  0.0   0.0      0.0  0.0     0.0     0.0    0.0   0.0   0.0  \n",
       "...     ...  ...   ...      ...  ...     ...     ...    ...   ...   ...  \n",
       "3258    0.0  0.0   0.0      0.0  0.0     0.0     0.0    0.0   0.0   0.0  \n",
       "3259    0.0  0.0   0.0      0.0  0.0     0.0     0.0    0.0   0.0   0.0  \n",
       "3260    0.0  0.0   0.0      0.0  0.0     0.0     0.0    0.0   0.0   0.0  \n",
       "3261    0.0  0.0   0.0      0.0  0.0     0.0     0.0    0.0   0.0   0.0  \n",
       "3262    0.0  0.0   0.0      0.0  0.0     0.0     0.0    0.0   0.0   0.0  \n",
       "\n",
       "[3263 rows x 5507 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix = vectorizer.transform(test_set['processed text'].tolist())\n",
    "test_tifi = pd.DataFrame(test_matrix.toarray(), columns=vectorizer.get_feature_names_out())   \n",
    "assert(test_tifi.columns == tfidf_df.columns).all()  \n",
    "test_tifi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Train test split </h1>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a 'target' column in your DataFrame\n",
    "X = tfidf_matrix  # Use the TF-IDF matrix as features\n",
    "y = df['target']  # Assuming 'target' is the column you want to predict\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Model comparison</h1>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting new model Logistic Regression LogisticRegression()\n",
      "\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.8024\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       874\n",
      "           1       0.82      0.69      0.75       649\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.81      0.79      0.79      1523\n",
      "weighted avg       0.80      0.80      0.80      1523\n",
      "\n",
      "Model saved as: Logistic Regression_model.joblib\n",
      "--------------------------------------------------\n",
      "starting new model Multinomial Naive Bayes MultinomialNB()\n",
      "\n",
      "Model: Multinomial Naive Bayes\n",
      "Accuracy: 0.8024\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       874\n",
      "           1       0.82      0.69      0.75       649\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.81      0.79      0.79      1523\n",
      "weighted avg       0.80      0.80      0.80      1523\n",
      "\n",
      "Model saved as: Multinomial Naive Bayes_model.joblib\n",
      "--------------------------------------------------\n",
      "starting new model Random Forest RandomForestClassifier()\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.7754\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81       874\n",
      "           1       0.76      0.69      0.73       649\n",
      "\n",
      "    accuracy                           0.78      1523\n",
      "   macro avg       0.77      0.77      0.77      1523\n",
      "weighted avg       0.77      0.78      0.77      1523\n",
      "\n",
      "Model saved as: Random Forest_model.joblib\n",
      "--------------------------------------------------\n",
      "starting new model Support Vector Machine Pipeline(steps=[('standardscaler', StandardScaler(with_mean=False)),\n",
      "                ('svc', SVC())])\n",
      "\n",
      "Model: Support Vector Machine\n",
      "Accuracy: 0.7741\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.82       874\n",
      "           1       0.84      0.58      0.69       649\n",
      "\n",
      "    accuracy                           0.77      1523\n",
      "   macro avg       0.79      0.75      0.76      1523\n",
      "weighted avg       0.79      0.77      0.77      1523\n",
      "\n",
      "Model saved as: Support Vector Machine_model.joblib\n",
      "--------------------------------------------------\n",
      "starting new model CatBoost <catboost.core.CatBoostClassifier object at 0x000002664F19F8D0>\n",
      "0:\tlearn: 0.6834564\ttotal: 172ms\tremaining: 17s\n",
      "1:\tlearn: 0.6776171\ttotal: 197ms\tremaining: 9.66s\n",
      "2:\tlearn: 0.6691418\ttotal: 222ms\tremaining: 7.17s\n",
      "3:\tlearn: 0.6627472\ttotal: 255ms\tremaining: 6.12s\n",
      "4:\tlearn: 0.6581506\ttotal: 287ms\tremaining: 5.45s\n",
      "5:\tlearn: 0.6540129\ttotal: 319ms\tremaining: 5s\n",
      "6:\tlearn: 0.6483018\ttotal: 353ms\tremaining: 4.69s\n",
      "7:\tlearn: 0.6427299\ttotal: 377ms\tremaining: 4.34s\n",
      "8:\tlearn: 0.6382700\ttotal: 401ms\tremaining: 4.06s\n",
      "9:\tlearn: 0.6349146\ttotal: 427ms\tremaining: 3.85s\n",
      "10:\tlearn: 0.6317076\ttotal: 452ms\tremaining: 3.65s\n",
      "11:\tlearn: 0.6277057\ttotal: 476ms\tremaining: 3.49s\n",
      "12:\tlearn: 0.6231750\ttotal: 501ms\tremaining: 3.35s\n",
      "13:\tlearn: 0.6200744\ttotal: 525ms\tremaining: 3.22s\n",
      "14:\tlearn: 0.6163831\ttotal: 551ms\tremaining: 3.12s\n",
      "15:\tlearn: 0.6134543\ttotal: 576ms\tremaining: 3.02s\n",
      "16:\tlearn: 0.6107584\ttotal: 602ms\tremaining: 2.94s\n",
      "17:\tlearn: 0.6088956\ttotal: 628ms\tremaining: 2.86s\n",
      "18:\tlearn: 0.6056430\ttotal: 658ms\tremaining: 2.8s\n",
      "19:\tlearn: 0.6037253\ttotal: 690ms\tremaining: 2.76s\n",
      "20:\tlearn: 0.6014447\ttotal: 722ms\tremaining: 2.72s\n",
      "21:\tlearn: 0.5987071\ttotal: 753ms\tremaining: 2.67s\n",
      "22:\tlearn: 0.5965336\ttotal: 780ms\tremaining: 2.61s\n",
      "23:\tlearn: 0.5941055\ttotal: 803ms\tremaining: 2.54s\n",
      "24:\tlearn: 0.5916007\ttotal: 827ms\tremaining: 2.48s\n",
      "25:\tlearn: 0.5901249\ttotal: 851ms\tremaining: 2.42s\n",
      "26:\tlearn: 0.5887038\ttotal: 875ms\tremaining: 2.37s\n",
      "27:\tlearn: 0.5871602\ttotal: 900ms\tremaining: 2.31s\n",
      "28:\tlearn: 0.5846575\ttotal: 931ms\tremaining: 2.28s\n",
      "29:\tlearn: 0.5826686\ttotal: 963ms\tremaining: 2.25s\n",
      "30:\tlearn: 0.5811671\ttotal: 995ms\tremaining: 2.21s\n",
      "31:\tlearn: 0.5795503\ttotal: 1.03s\tremaining: 2.18s\n",
      "32:\tlearn: 0.5777930\ttotal: 1.05s\tremaining: 2.14s\n",
      "33:\tlearn: 0.5759781\ttotal: 1.08s\tremaining: 2.09s\n",
      "34:\tlearn: 0.5746296\ttotal: 1.1s\tremaining: 2.05s\n",
      "35:\tlearn: 0.5734763\ttotal: 1.13s\tremaining: 2.01s\n",
      "36:\tlearn: 0.5718407\ttotal: 1.15s\tremaining: 1.96s\n",
      "37:\tlearn: 0.5708445\ttotal: 1.18s\tremaining: 1.92s\n",
      "38:\tlearn: 0.5691899\ttotal: 1.2s\tremaining: 1.88s\n",
      "39:\tlearn: 0.5677678\ttotal: 1.23s\tremaining: 1.84s\n",
      "40:\tlearn: 0.5664065\ttotal: 1.25s\tremaining: 1.8s\n",
      "41:\tlearn: 0.5648294\ttotal: 1.29s\tremaining: 1.78s\n",
      "42:\tlearn: 0.5629686\ttotal: 1.32s\tremaining: 1.75s\n",
      "43:\tlearn: 0.5618764\ttotal: 1.35s\tremaining: 1.72s\n",
      "44:\tlearn: 0.5607351\ttotal: 1.38s\tremaining: 1.69s\n",
      "45:\tlearn: 0.5596179\ttotal: 1.41s\tremaining: 1.65s\n",
      "46:\tlearn: 0.5582253\ttotal: 1.44s\tremaining: 1.62s\n",
      "47:\tlearn: 0.5568672\ttotal: 1.47s\tremaining: 1.59s\n",
      "48:\tlearn: 0.5556639\ttotal: 1.5s\tremaining: 1.56s\n",
      "49:\tlearn: 0.5542984\ttotal: 1.54s\tremaining: 1.54s\n",
      "50:\tlearn: 0.5525659\ttotal: 1.57s\tremaining: 1.51s\n",
      "51:\tlearn: 0.5515248\ttotal: 1.6s\tremaining: 1.48s\n",
      "52:\tlearn: 0.5506354\ttotal: 1.64s\tremaining: 1.46s\n",
      "53:\tlearn: 0.5490129\ttotal: 1.67s\tremaining: 1.43s\n",
      "54:\tlearn: 0.5477655\ttotal: 1.71s\tremaining: 1.4s\n",
      "55:\tlearn: 0.5463580\ttotal: 1.74s\tremaining: 1.37s\n",
      "56:\tlearn: 0.5451467\ttotal: 1.77s\tremaining: 1.34s\n",
      "57:\tlearn: 0.5442744\ttotal: 1.81s\tremaining: 1.31s\n",
      "58:\tlearn: 0.5436272\ttotal: 1.84s\tremaining: 1.28s\n",
      "59:\tlearn: 0.5422585\ttotal: 1.86s\tremaining: 1.24s\n",
      "60:\tlearn: 0.5412310\ttotal: 1.89s\tremaining: 1.21s\n",
      "61:\tlearn: 0.5403274\ttotal: 1.91s\tremaining: 1.17s\n",
      "62:\tlearn: 0.5393743\ttotal: 1.94s\tremaining: 1.14s\n",
      "63:\tlearn: 0.5386670\ttotal: 1.97s\tremaining: 1.11s\n",
      "64:\tlearn: 0.5377902\ttotal: 1.99s\tremaining: 1.07s\n",
      "65:\tlearn: 0.5369320\ttotal: 2.02s\tremaining: 1.04s\n",
      "66:\tlearn: 0.5359075\ttotal: 2.07s\tremaining: 1.02s\n",
      "67:\tlearn: 0.5351135\ttotal: 2.11s\tremaining: 991ms\n",
      "68:\tlearn: 0.5340099\ttotal: 2.14s\tremaining: 961ms\n",
      "69:\tlearn: 0.5331873\ttotal: 2.16s\tremaining: 927ms\n",
      "70:\tlearn: 0.5323000\ttotal: 2.19s\tremaining: 894ms\n",
      "71:\tlearn: 0.5313038\ttotal: 2.21s\tremaining: 861ms\n",
      "72:\tlearn: 0.5301101\ttotal: 2.24s\tremaining: 828ms\n",
      "73:\tlearn: 0.5293774\ttotal: 2.26s\tremaining: 795ms\n",
      "74:\tlearn: 0.5284625\ttotal: 2.29s\tremaining: 762ms\n",
      "75:\tlearn: 0.5275151\ttotal: 2.31s\tremaining: 730ms\n",
      "76:\tlearn: 0.5264444\ttotal: 2.34s\tremaining: 698ms\n",
      "77:\tlearn: 0.5256588\ttotal: 2.36s\tremaining: 667ms\n",
      "78:\tlearn: 0.5244715\ttotal: 2.39s\tremaining: 635ms\n",
      "79:\tlearn: 0.5234765\ttotal: 2.42s\tremaining: 604ms\n",
      "80:\tlearn: 0.5224362\ttotal: 2.44s\tremaining: 573ms\n",
      "81:\tlearn: 0.5214002\ttotal: 2.47s\tremaining: 543ms\n",
      "82:\tlearn: 0.5206963\ttotal: 2.5s\tremaining: 512ms\n",
      "83:\tlearn: 0.5198131\ttotal: 2.53s\tremaining: 482ms\n",
      "84:\tlearn: 0.5188262\ttotal: 2.56s\tremaining: 452ms\n",
      "85:\tlearn: 0.5180737\ttotal: 2.59s\tremaining: 422ms\n",
      "86:\tlearn: 0.5169345\ttotal: 2.63s\tremaining: 392ms\n",
      "87:\tlearn: 0.5159687\ttotal: 2.66s\tremaining: 362ms\n",
      "88:\tlearn: 0.5147611\ttotal: 2.69s\tremaining: 333ms\n",
      "89:\tlearn: 0.5140674\ttotal: 2.72s\tremaining: 303ms\n",
      "90:\tlearn: 0.5131087\ttotal: 2.75s\tremaining: 272ms\n",
      "91:\tlearn: 0.5122716\ttotal: 2.79s\tremaining: 242ms\n",
      "92:\tlearn: 0.5111877\ttotal: 2.82s\tremaining: 212ms\n",
      "93:\tlearn: 0.5102052\ttotal: 2.85s\tremaining: 182ms\n",
      "94:\tlearn: 0.5089473\ttotal: 2.88s\tremaining: 152ms\n",
      "95:\tlearn: 0.5077477\ttotal: 2.91s\tremaining: 121ms\n",
      "96:\tlearn: 0.5065071\ttotal: 2.95s\tremaining: 91.2ms\n",
      "97:\tlearn: 0.5055289\ttotal: 2.98s\tremaining: 60.8ms\n",
      "98:\tlearn: 0.5046301\ttotal: 3.01s\tremaining: 30.4ms\n",
      "99:\tlearn: 0.5035417\ttotal: 3.05s\tremaining: 0us\n",
      "\n",
      "Model: CatBoost\n",
      "Accuracy: 0.7617\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.92      0.82       874\n",
      "           1       0.83      0.55      0.66       649\n",
      "\n",
      "    accuracy                           0.76      1523\n",
      "   macro avg       0.78      0.73      0.74      1523\n",
      "weighted avg       0.78      0.76      0.75      1523\n",
      "\n",
      "Model saved as: CatBoost_model.joblib\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Multinomial Naive Bayes': MultinomialNB(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Support Vector Machine': make_pipeline(StandardScaler(with_mean=False), SVC()),\n",
    "    'CatBoost': CatBoostClassifier(iterations=100, depth=5, learning_rate=0.1, loss_function='Logloss')\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "for name, model in models.items():\n",
    "    print('starting new model', name, model)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate model performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # Save the trained model\n",
    "    model_filename = f'{name}_model.joblib'\n",
    "    joblib.dump(model, model_filename)\n",
    "    \n",
    "    # Display results\n",
    "    print(f'\\nModel: {name}')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print('Classification Report:\\n', report)\n",
    "    print(f'Model saved as: {model_filename}')\n",
    "    print('--------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best accuracy of 80.24% acchieved Multinomial Naive Bayes model (slightly better recall than Logistic regression)\n",
    "### re-evaluation of the model can be found in part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
